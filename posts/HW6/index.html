<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.541">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jamie">
<meta name="dcterms.date" content="2024-03-11">

<title>Jamie’s Blog - Fake News Detection</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Jamie’s Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Fake News Detection</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">HOMEWORK</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Jamie </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 11, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="table-of-contents" class="level1">
<h1>Table of Contents</h1>
<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">1. Introduction</h3>
</section>
<section id="data-acquisition" class="level3">
<h3 class="anchored" data-anchor-id="data-acquisition">2. Data Acquisition</h3>
</section>
<section id="data-preparation" class="level3">
<h3 class="anchored" data-anchor-id="data-preparation">3. Data Preparation</h3>
</section>
<section id="model-creation-model1-using-title-model2-using-text-model3-using-title-text" class="level3">
<h3 class="anchored" data-anchor-id="model-creation-model1-using-title-model2-using-text-model3-using-title-text">4. Model Creation: Model1 (using Title), Model2 (using Text), Model3 (using Title + Text)</h3>
</section>
<section id="model-training" class="level3">
<h3 class="anchored" data-anchor-id="model-training">5. Model Training</h3>
</section>
<section id="model-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="model-evaluation">6. Model Evaluation</h3>
</section>
<section id="embeding-visualization" class="level3">
<h3 class="anchored" data-anchor-id="embeding-visualization">7. Embeding Visualization</h3>
<div id="cell-2" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the default Plotly renderer to "iframe"</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.io <span class="im">as</span> pio</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>pio.renderers.default <span class="op">=</span> <span class="st">"iframe"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="introduction-1" class="level1">
<h1>1. Introduction</h1>
<p>In today’s digital age, the spread of misinformation and fake news has become a major concern. With the vast amount of information available online, it has become increasingly challenging to distinguish between credible sources and those that peddle falsehoods. This problem has far-reaching consequences, from swaying public opinion to influencing political outcomes.</p>
<p>To combat this issue, researchers and data scientists have been exploring various techniques to automate the detection of fake news. One promising approach involves the use of deep learning, a subfield of machine learning that has proven remarkably effective in tasks such as image recognition, natural language processing, and predictive modeling.</p>
<p>In this blog post, we’ll explore the application of deep learning, specifically using the Keras library, to build models capable of identifying fake news articles. We’ll be implementing three different models, each leveraging different aspects of the news article:</p>
<ol type="1">
<li><p><strong>Model 1 (Using Title)</strong>: This model will focus solely on the title of the news article, aiming to capture any potential signals or patterns that might indicate whether the content is legitimate or fabricated.</p></li>
<li><p><strong>Model 2 (Using Text)</strong>: In contrast, this model will analyze the body text of the news article, taking into account the writing style, word choice, and overall content to make its prediction.</p></li>
<li><p><strong>Model 3 (Using Title + Text)</strong>: The third model will combine the strengths of the previous two, incorporating both the title and the body text to make a more informed decision about the veracity of the news article.</p></li>
</ol>
<p>By comparing the performance of these three models, we’ll gain insights into the relative importance of different components of a news article in determining its credibility. Additionally, we’ll explore techniques for optimizing these models, such as data preprocessing, feature engineering, and hyperparameter tuning.</p>
<p>Fake news detection is a complex and multifaceted challenge, but the application of deep learning techniques holds great promise in tackling this issue. Join us as we delve into the world of deep learning and explore its potential in combating the spread of misinformation.</p>
<div id="cell-5" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import pakeages</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> string</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> layers</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> losses</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> keras</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> TextVectorization</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="co"># for embedding viz</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.io <span class="im">as</span> pio</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>pio.templates.default <span class="op">=</span> <span class="st">"plotly_white"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-6" class="cell" data-outputid="6f77af97-2bfd-4376-c055-6b4a5410e8b4" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install keras <span class="op">--</span>upgrade</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.0.5)
Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)
Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.25.2)
Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)
Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.7)
Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.9.0)
Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras) (0.1.8)
Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.2.0)
Requirement already satisfied: markdown-it-py&gt;=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;keras) (3.0.0)
Requirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;keras) (2.16.1)
Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py&gt;=2.2.0-&gt;rich-&gt;keras) (0.1.2)</code></pre>
</div>
</div>
<div id="cell-7" class="cell" data-outputid="e2c48c90-520e-4d72-bc41-57f788543763" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(keras.__version__)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>3.0.5</code></pre>
</div>
</div>
<div id="cell-8" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"KERAS_BACKEND"</span>] <span class="op">=</span> <span class="st">"tensorflow"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="data-acquisition-1" class="level1">
<h1>2. Data Acquisition</h1>
<p>Our data for this assignment comes from the article</p>
<p>Ahmed H, Traore I, Saad S. (2017) “Detection of Online Fake News Using N-Gram Analysis and Machine Learning Techniques. In: Traore I., Woungang I., Awad A. (eds) Intelligent, Secure, and Dependable Systems in Distributed and Cloud Environments. ISDDC 2017. Lecture Notes in Computer Science, vol 10618. Springer, Cham (pp.&nbsp;127-138).</p>
<div id="cell-11" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>train_url <span class="op">=</span> <span class="st">"https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_train.csv?raw=true"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The dataset hosted a training data set at the below URL. You can either read it into Python directly (via pd.read_csv()) or download it to your computer and read it from disk. This would be our training dataset.</p>
<div id="cell-13" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(train_url)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-14" class="cell" data-outputid="91e39316-aee1-423b-e51e-8843d0086893" data-execution_count="8">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>data.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">

  <div id="df-8ded98ac-46cb-46d2-b532-8e1b2d20b262" class="colab-df-container">
    <div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Unnamed: 0</th>
<th data-quarto-table-cell-role="th">title</th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">fake</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>17366</td>
<td>Merkel: Strong result for Austria's FPO 'big c...</td>
<td>German Chancellor Angela Merkel said on Monday...</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>5634</td>
<td>Trump says Pence will lead voter fraud panel</td>
<td>WEST PALM BEACH, Fla.President Donald Trump sa...</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>17487</td>
<td>JUST IN: SUSPECTED LEAKER and “Close Confidant...</td>
<td>On December 5, 2017, Circa s Sara Carter warne...</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>12217</td>
<td>Thyssenkrupp has offered help to Argentina ove...</td>
<td>Germany s Thyssenkrupp, has offered assistance...</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5535</td>
<td>Trump say appeals court decision on travel ban...</td>
<td>President Donald Trump on Thursday called the ...</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-8ded98ac-46cb-46d2-b532-8e1b2d20b262')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-8ded98ac-46cb-46d2-b532-8e1b2d20b262 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-8ded98ac-46cb-46d2-b532-8e1b2d20b262');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-a6643aca-c737-4f7a-bf7e-5b1bf9206859">
  <button class="colab-df-quickchart" onclick="quickchart('df-a6643aca-c737-4f7a-bf7e-5b1bf9206859')" title="Suggest charts" style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-a6643aca-c737-4f7a-bf7e-5b1bf9206859 button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

    </div>
  </div>
</div>
</div>
<p>Each row of the data corresponds to an article. The <code>title</code> column gives the title of the article, while the <code>text</code> column gives the full article text. The final column, called <code>fake</code>, is 0 if the article is true and 1 if the article contains fake news, as determined by the authors of the paper above.</p>
<div id="cell-16" class="cell" data-outputid="c0d48e31-738a-48af-c25c-3d7d43c3968c" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>data.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>(22449, 4)</code></pre>
</div>
</div>
<div id="cell-17" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> data.copy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Always copy from the original dataset, in case you make some inreversible changes and do not want to load data again.</p>
</section>
<section id="data-preparation-1" class="level1">
<h1>3. Data Preparation</h1>
<p>As you can see from the preview of the dataset, we need to perform some preprocessing steps on the ‘title’ and ‘text’ columns. These steps are essential for improving the performance and accuracy of our machine learning models. Let me explain the reasons behind each step:</p>
<ol type="1">
<li><p><strong>Change all characters into lowercase</strong>: This step ensures consistency in the text data, as it eliminates the possibility of treating the same word differently based on its capitalization. For example, “News” and “news” would be treated as different words without lowercasing, which is undesirable for text analysis tasks.</p></li>
<li><p><strong>Remove stopwords</strong>: Stopwords are common words in a language that carry little or no meaningful information, such as articles (e.g., “a,” “an,” “the”), prepositions (e.g., “in,” “on,” “at”), conjunctions (e.g., “and,” “but,” “or”), and pronouns (e.g., “it,” “he,” “she”). Removing these words helps to reduce noise in the text data and focuses the analysis on the more meaningful words, which can improve the model’s ability to capture the essence of the content.</p></li>
<li><p><strong>Convert into TensorFlow Dataset</strong>: TensorFlow Datasets are a convenient way to represent and handle data in TensorFlow, making it easier to load, preprocess, and iterate over the data during training and evaluation. By converting the preprocessed data into a TensorFlow Dataset, we can take advantage of various features and optimizations provided by TensorFlow, such as batching, shuffling, and efficient data loading.</p></li>
</ol>
<p>By performing these preprocessing steps, we aim to clean and prepare the text data in a way that makes it more suitable for our machine learning models. Lowercasing ensures consistent treatment of words, removing stopwords reduces noise, and converting to a TensorFlow Dataset streamlines the data handling process. These steps are commonly applied in natural language processing tasks and can significantly improve the performance and accuracy of text-based machine learning models.</p>
<p>To do this, we write a function called <code>make_dataset</code>. You can consider it as a pipline since you might want to apply it later on the test dataset to make sure the correspondence.</p>
<div id="cell-21" class="cell" data-outputid="2d976766-3009-47d8-845f-149bd5a38fac" data-execution_count="11">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import stopwords with nltk.</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'stopwords'</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> stopwords</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[nltk_data] Downloading package stopwords to /root/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!</code></pre>
</div>
</div>
<div id="cell-22" class="cell" data-outputid="0f59f982-2634-4b2d-b15a-19401664d76d" data-execution_count="12">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>stop_words <span class="op">=</span> <span class="bu">set</span>(stopwords.words(<span class="st">'english'</span>))</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(stop_words)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'t', 'who', 'so', 'where', 'about', 'did', 'yours', 'm', 'during', 'any', 'itself', 'theirs', 'd', 'those', 'and', 'you', 'will', 'won', 'both', 'through', 'his', "mightn't", 'by', 'i', 'him', 'mightn', 'why', "wasn't", 'aren', 'been', 'her', 'is', 'yourselves', 'this', 'an', "you're", 'there', "shouldn't", 'y', 'against', 'out', 's', 'hasn', 'more', 'over', 'our', "couldn't", 'your', 'on', 'same', 'because', 'isn', 'while', 'mustn', 'shouldn', 'ain', 'only', 'some', 'a', 'has', 'than', "doesn't", 'other', 'their', 'shan', 'from', 'in', 'for', 'don', 'wouldn', 'do', "don't", 'does', 'which', 'not', "didn't", 'they', 'that', 'having', "shan't", "won't", 'too', 'of', 'below', "wouldn't", 'when', 'with', 'haven', 'or', 'very', 'be', 'as', 'own', 'above', 'just', 'are', 'them', 'needn', 'wasn', 'these', "haven't", "aren't", 'off', 'being', 'had', "that'll", 'after', "you've", 'it', 'down', 'if', "it's", 'me', 'whom', 'was', "mustn't", 'hadn', 'again', 'myself', 'herself', 'until', "she's", 'up', 'can', "you'll", 'the', 'few', 'should', 'ma', 'himself', 'o', "needn't", "hadn't", 'doesn', "should've", 'yourself', 've', 'didn', 'have', 'now', 'further', 'its', "you'd", 'here', 'weren', 'then', 're', 'she', 'all', 'he', "weren't", 'll', 'what', 'ourselves', 'but', 'most', 'couldn', 'doing', 'no', 'were', 'at', 'hers', 'themselves', 'am', "hasn't", 'between', 'how', 'ours', 'each', 'to', 'under', 'we', 'such', 'into', "isn't", 'my', 'nor', 'once', 'before'}</code></pre>
</div>
</div>
<div id="cell-23" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_dataset(df):</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>   <span class="co">"""</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co">   Preprocesses the given DataFrame and creates a TensorFlow Dataset.</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co">   Args:</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co">       df (pandas.DataFrame): The input DataFrame containing the news articles and their corresponding labels.</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co">   Returns:</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co">       tf.data.Dataset: A TensorFlow Dataset containing the preprocessed data.</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co">   This function performs the following preprocessing steps:</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="co">   1. Converts the 'text' and 'title' columns to lowercase.</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="co">   2. Removes stop words from the 'title' and 'text' columns.</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="co">   3. Creates a TensorFlow Dataset from the preprocessed data, with 'title' and 'text' as features</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="co">      and 'fake' as the label.</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="co">   """</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>   df[<span class="st">'text'</span>] <span class="op">=</span> df[<span class="st">'text'</span>].<span class="bu">str</span>.lower()</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>   df[<span class="st">'title'</span>] <span class="op">=</span> df[<span class="st">'title'</span>].<span class="bu">str</span>.lower()</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>   df[<span class="st">'title'</span>] <span class="op">=</span> df[<span class="st">'title'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="st">' '</span>.join([word <span class="cf">for</span> word <span class="kw">in</span> x.split() <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> (stop_words)]))</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>   df[<span class="st">'text'</span>] <span class="op">=</span> df[<span class="st">'text'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="st">' '</span>.join([word <span class="cf">for</span> word <span class="kw">in</span> x.split() <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> (stop_words)]))</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>   tf_df <span class="op">=</span> tf.data.Dataset.from_tensor_slices(({<span class="st">'title'</span>: df[<span class="st">"title"</span>], <span class="st">'text'</span>: df[<span class="st">"text"</span>]}, df[<span class="st">"fake"</span>]))</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>   <span class="cf">return</span> tf_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This will construct and return a tf.data.Dataset with two inputs(title, text) and one output(fake). Now we get our data!</p>
<div id="cell-25" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>tf_df <span class="op">=</span> make_dataset(df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You may wish to batch your Dataset prior to returning it, which can be done like this: my_data_set.batch(100). Batching causes your model to train on chunks of data rather than individual rows. This can sometimes reduce accuracy, but can also greatly increase the speed of training. Finding a balance is key. I found batches of 100 rows to work well. This time I wou’t do it.</p>
<div id="cell-27" class="cell" data-outputid="200ab422-36cf-4e87-b78b-4ed3e99c2e43" data-execution_count="15">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>tf_df <span class="op">=</span> tf_df.shuffle(buffer_size <span class="op">=</span> <span class="bu">len</span>(tf_df), reshuffle_each_iteration<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>train_size <span class="op">=</span> <span class="bu">int</span>(<span class="fl">0.8</span><span class="op">*</span><span class="bu">len</span>(tf_df))</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>val_size   <span class="op">=</span> <span class="bu">int</span>(<span class="fl">0.2</span><span class="op">*</span><span class="bu">len</span>(tf_df))</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span> tf_df.take(train_size)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>val   <span class="op">=</span> tf_df.skip(train_size).take(val_size)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(train), <span class="bu">len</span>(val)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>(17959, 4489)</code></pre>
</div>
</div>
<p>To ensure that the model is exposed to a diverse set of examples during training and can be evaluated on unseen data during validation, we do the following:</p>
<p><code>tf_df = tf_df.shuffle(buffer_size=len(tf_df), reshuffle_each_iteration=False)</code>: shuffles the <code>tf_df</code> TensorFlow Dataset. Shuffling the data is an important step in machine learning, as it helps to introduce randomness and prevent the model from learning any patterns specific to the order of the data. The <code>buffer_size=len(tf_df)</code> parameter specifies that the entire dataset should be loaded into the buffer for shuffling. <code>reshuffle_each_iteration=False</code> means that the data will be shuffled once, and the same shuffled order will be used for each iteration or epoch during training.</p>
<p><code>train_size = int(0.8 * len(tf_df))</code>: calculates the size of the training dataset by taking 80% of the total dataset size. The <code>int()</code> function is used to convert the result to an integer, as the dataset indexing requires integer values.</p>
<p><code>val_size = int(0.2 * len(tf_df))</code>: Similarly, this line calculates the size of the validation dataset by taking 20% of the total dataset size.</p>
<p><code>train = tf_df.take(train_size)</code>: creates a new TensorFlow Dataset <code>train</code> by taking the first <code>train_size</code> elements from <code>tf_df</code>. This subset will be used for training the machine learning model.</p>
<p><code>val = tf_df.skip(train_size).take(val_size)</code>: creates a new TensorFlow Dataset <code>val</code> by skipping the first <code>train_size</code> elements from <code>tf_df</code> and then taking the next <code>val_size</code> elements. This subset will be used for validation during the training process, to evaluate the model’s performance on unseen data.</p>
<div id="cell-29" class="cell" data-outputid="59a9ccfa-21e8-484f-8530-31139348f0b3" data-execution_count="16">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>df.fake.value_counts()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>1    11740
0    10709
Name: fake, dtype: int64</code></pre>
</div>
</div>
<div id="cell-30" class="cell" data-outputid="6bb9c03e-0550-4233-c8be-2618727db3c7" data-execution_count="17">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="dv">11740</span> <span class="op">/</span> (<span class="dv">11740</span><span class="op">+</span><span class="dv">10709</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>0.522963160942581</code></pre>
</div>
</div>
<p>Do you remember Base rate that we mentioned last time? Base rate refers to the accuracy of a model that always makes the same guess (for example, such a model might always say “fake news!”). The base rate for this case would be 0.522 as calculated above through dividing number of most occurency (1) by number of 0s.</p>
<p>Vectorization is the process of converting text into numerical representations, allowing machine learning models to process and understand textual data. In this case, we use a frequency ranking approach, where each word is replaced by its rank based on its frequency of occurrence within the dataset. For example, “Poll: Penguins Best Bird” might be represented as [708, 1567, 89, 632], where the numbers correspond to the frequency ranks of “poll”, “penguins”, “best”, and “bird” respectively.</p>
<p>TensorFlow provides a <code>TextVectorization</code> layer that handles this process efficiently. It takes the standardized text data as input and converts it into numerical vectors suitable for training and inference. This step is crucial for feeding textual data into machine learning models that operate on numerical inputs.</p>
<div id="cell-33" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co">#preparing a text vectorization layer for tf model</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>max_tokens <span class="op">=</span> <span class="dv">2000</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> standardization(input_data):</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>    lowercase <span class="op">=</span> tf.strings.lower(input_data)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    no_punctuation <span class="op">=</span> tf.strings.regex_replace(lowercase,</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>                                  <span class="st">'[</span><span class="sc">%s</span><span class="st">]'</span> <span class="op">%</span> re.escape(string.punctuation),<span class="st">''</span>)</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> no_punctuation</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a><span class="co"># replace each words by its frequency rank in the data</span></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>vectorize_layer <span class="op">=</span> TextVectorization(</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>    standardize<span class="op">=</span>standardization,</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>    max_tokens<span class="op">=</span>max_tokens, <span class="co"># only consider this many words</span></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>    output_mode<span class="op">=</span><span class="st">'int'</span>,</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>    output_sequence_length<span class="op">=</span><span class="dv">500</span>)</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>texts <span class="op">=</span> train.<span class="bu">map</span>(<span class="kw">lambda</span> x, y: x[<span class="st">'title'</span>] <span class="op">+</span> <span class="st">' '</span> <span class="op">+</span> x[<span class="st">'text'</span>])</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>vectorize_layer.adapt(texts)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Since we used <code>Embedding</code> in the following model, we might need to expand dimision from 2D to 3D. If you want to do it in another way, here is one option:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tf.data.Dataset.from_tensor_slices(</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    (</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>            <span class="st">"title"</span> : df[[<span class="st">"title"</span>]],</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>            <span class="st">"text"</span> : df[[<span class="st">'text'</span>]]</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>            <span class="st">"fake"</span> : df[[<span class="st">"fake"</span>]]</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="cell-35" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># increase the dim</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> expand_dim(data, label):</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    title <span class="op">=</span> tf.expand_dims(data[<span class="st">'title'</span>], <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> tf.expand_dims(data[<span class="st">'text'</span>], <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">'title'</span>: title, <span class="st">'text'</span>: text}, [label]</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span> train.<span class="bu">map</span>(expand_dim)</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>val <span class="op">=</span> val.<span class="bu">map</span>(expand_dim)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Ok, let’s create our models!</p>
</section>
<section id="model-creation-model1-using-title-model2-using-text-model3-using-title-text-1" class="level1">
<h1>4. Model Creation: Model1 (using Title), Model2 (using Text), Model3 (using Title + Text)</h1>
<p>We start by specifying the two kinds of <code>keras.Input</code> for our model. You should have one input for each qualitatively distinct “kind” of predictor data. All the parameters here are important:</p>
<ul>
<li><code>shape</code> should describe the shape of a single item of data. For example, the <code>lyrics</code> column contains just one entry for each song, so the shape is <code>(1,)</code> (a tuple of length 1). On the other hand, there are <code>len(scalars) = 22</code> distinct columns of scalar scores.</li>
<li>the <code>name</code> should be some descriptive name that you’re able to remember for later.</li>
<li>The <code>dtype</code> specifies the kind of data contained in each of the input tensors.</li>
</ul>
<p>By creating these separate input layers for ‘title’ and ‘text’, we can feed the data into the model independently and allow the model to learn the relevant features from each input source. This approach is useful when dealing with different types of input data or when you want to process different parts of the input separately before combining them later in the model.</p>
<div id="cell-39" class="cell" data-outputid="f653d50c-e6bf-45fa-9ad1-74a50bf0c6e4" data-execution_count="20">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define input layers for title and text</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>title_input <span class="op">=</span> tf.keras.Input(shape<span class="op">=</span>(<span class="dv">1</span>, ), dtype<span class="op">=</span>tf.string, name<span class="op">=</span><span class="st">'title'</span>)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>text_input <span class="op">=</span> tf.keras.Input(shape<span class="op">=</span>(<span class="dv">1</span>, ), dtype<span class="op">=</span>tf.string, name<span class="op">=</span><span class="st">'text'</span>)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(title_input.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(None, 1)</code></pre>
</div>
</div>
<p>First, let’s write a pipeline for the lyrics.</p>
<p>Last time we use Sequential API, this time we will use Functional API.</p>
<p>Keras provides two different APIs for building neural network models: the Sequential API and the Functional API. The main difference between these two APIs lies in their approach to model construction and the level of flexibility they offer.</p>
<p><strong>Sequential API</strong>: - The Sequential API is a linear stack of layers, where each layer is added sequentially to the model. - It is best suited for simple, feed-forward models where the data flows from the input layer through the hidden layers to the output layer. - The architecture is defined by simply stacking the layers one after the other, making it easy to construct and understand. - Example:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">64</span>, input_dim<span class="op">=</span>input_size))</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>model.add(Activation(<span class="st">'relu'</span>))</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">10</span>))</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>model.add(Activation(<span class="st">'softmax'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Functional API</strong>: - The Functional API is a more flexible and powerful way to build complex models with non-linear architectures, such as models with multiple inputs or outputs, models with shared layers, or models with residual connections. - It allows you to define complex computational graphs by connecting layers with tensors, enabling the creation of models with arbitrary architectures. - The model is defined by specifying the input tensors and then using these tensors to create the output tensors by applying layers and operations. - Example:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> Input(shape<span class="op">=</span>(input_size,))</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(inputs)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">'softmax'</span>)(x)</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In summary, the Sequential API is more beginner-friendly and suitable for simple, linear models, while the Functional API offers more flexibility and control for building complex models with non-linear architectures. The Functional API is generally preferred for advanced models, as it allows for greater customization and reusability of components within the model.</p>
<p>It’s worth noting that both APIs eventually create the same Keras model object, and the choice between them depends on the complexity of the model you want to build and your personal preference for the coding style.</p>
<div id="cell-41" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># passes the title_input tensor through the vectorize_layer</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>title_features <span class="op">=</span> vectorize_layer(title_input)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>title_features <span class="op">=</span> layers.Embedding(<span class="dv">2000</span>, <span class="dv">3</span>, name <span class="op">=</span> <span class="st">"title_embedding"</span>)(title_features)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>title_features <span class="op">=</span> layers.Dropout(<span class="fl">0.2</span>)(title_features)</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>title_features <span class="op">=</span> layers.GlobalAveragePooling1D()(title_features)</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>title_features <span class="op">=</span> layers.Dropout(<span class="fl">0.2</span>)(title_features)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>title_features <span class="op">=</span> layers.Dense(<span class="dv">32</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(title_features)</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>text_features <span class="op">=</span> vectorize_layer(text_input)</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>text_features <span class="op">=</span> layers.Embedding(<span class="dv">2000</span>, <span class="dv">3</span>, name <span class="op">=</span> <span class="st">"text_embedding"</span>)(text_features)</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>text_features <span class="op">=</span> layers.Dropout(<span class="fl">0.2</span>)(text_features)</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>text_features <span class="op">=</span> layers.GlobalAveragePooling1D()(text_features)</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>text_features <span class="op">=</span> layers.Dropout(<span class="fl">0.2</span>)(text_features)</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>text_features <span class="op">=</span> layers.Dense(<span class="dv">32</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(text_features)</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>main1 <span class="op">=</span> layers.Dense(<span class="dv">32</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(title_features)</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>output1 <span class="op">=</span> layers.Dense(<span class="dv">2</span>, name <span class="op">=</span> <span class="st">"fake"</span>)(main1)</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>model1 <span class="op">=</span> keras.Model(</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> title_input,</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> output1</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>main2 <span class="op">=</span> layers.Dense(<span class="dv">32</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(text_features)</span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>output2 <span class="op">=</span> layers.Dense(<span class="dv">2</span>, name <span class="op">=</span> <span class="st">"fake"</span>)(main2)</span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>model2 <span class="op">=</span> keras.Model(</span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> text_input,</span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> output2</span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>main3 <span class="op">=</span> layers.concatenate([title_features, text_features], axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a>main3 <span class="op">=</span> layers.Dense(<span class="dv">32</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(main3)</span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a>output3 <span class="op">=</span> layers.Dense(<span class="dv">2</span>, name <span class="op">=</span> <span class="st">"fake"</span>)(main3)</span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a>model3 <span class="op">=</span> keras.Model(</span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> [title_input, text_input],</span>
<span id="cb33-35"><a href="#cb33-35" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> output3</span>
<span id="cb33-36"><a href="#cb33-36" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here we defines three separate models with difference input but same layers.</p>
<p>Model1 (using Title)</p>
<p>Model2 (using Text)</p>
<p>Model3 (using Title + Text)</p>
<p>Let’s go through each layer used in the code:</p>
<ol type="1">
<li><strong>TextVectorization Layer</strong>:
<ul>
<li><code>title_features = vectorize_layer(title_input)</code></li>
<li><code>text_features = vectorize_layer(text_input)</code></li>
<li>This layer converts the input text into numerical representations, such as frequency rank vectors or one-hot encodings.</li>
</ul></li>
<li><strong>Embedding Layer</strong>:
<ul>
<li><code>title_features = layers.Embedding(2000, 3, name="title_embedding")(title_features)</code></li>
<li><code>text_features = layers.Embedding(2000, 3, name="text_embedding")(text_features)</code></li>
<li>This layer maps the numerical representations of words/tokens to dense vector representations (embeddings) of a fixed size (in this case, 3).</li>
<li>The <code>2000</code> parameter specifies the vocabulary size (maximum number of unique words/tokens).</li>
</ul></li>
<li><strong>Dropout Layer</strong>:
<ul>
<li><code>title_features = layers.Dropout(0.2)(title_features)</code></li>
<li><code>text_features = layers.Dropout(0.2)(text_features)</code></li>
<li>This layer randomly sets a fraction (0.2 or 20%) of the input units to 0 during training, which helps prevent overfitting by introducing noise and regularization.</li>
</ul></li>
<li><strong>GlobalAveragePooling1D Layer</strong>:
<ul>
<li><code>title_features = layers.GlobalAveragePooling1D()(title_features)</code></li>
<li><code>text_features = layers.GlobalAveragePooling1D()(text_features)</code></li>
<li>This layer computes the average of the input vectors across the sequence dimension (1D), effectively reducing the representation to a single vector that captures the overall meaning of the input sequence.</li>
</ul></li>
<li><strong>Dense Layer</strong>:
<ul>
<li><code>title_features = layers.Dense(32, activation='relu')(title_features)</code></li>
<li><code>text_features = layers.Dense(32, activation='relu')(text_features)</code></li>
<li>This is a fully-connected layer that applies a linear transformation to the input and then applies a ReLU (Rectified Linear Unit) activation function.</li>
<li>The <code>32</code> parameter specifies the number of output units in the dense layer.</li>
</ul></li>
</ol>
<p>By applying these layers to the ‘title’ and ‘text’ inputs separately, the code generates separate feature representations for each input source.</p>
<p>By the following code, you can see how the data have gone through each layers.</p>
<div id="cell-44" class="cell" data-outputid="779a3f65-0716-4352-cf00-8beea6c4e5e4" data-execution_count="22">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>keras.utils.plot_model(model1, <span class="st">"classifier_model_with_title_only.png"</span>, show_shapes<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>                       show_layer_names<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>                       show_layer_activations<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-23-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-45" class="cell" data-outputid="22577421-5f3d-456b-c7fd-a65dafa525e0" data-execution_count="23">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>keras.utils.plot_model(model2, <span class="st">"classifier_model_with_text_only.png"</span>, show_shapes<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>                       show_layer_names<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>                       show_layer_activations<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-24-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-46" class="cell" data-outputid="d04d5cc8-4129-45cd-f346-6a008027e1f1" data-execution_count="24">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>keras.utils.plot_model(model3, <span class="st">"classifier_model_with_title_and_text.png"</span>, show_shapes<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>                       show_layer_names<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>                       show_layer_activations<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-25-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-47" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>model1.<span class="bu">compile</span>(optimizer <span class="op">=</span> <span class="st">"adam"</span>,</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>              loss <span class="op">=</span> losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>              metrics<span class="op">=</span>[<span class="st">'accuracy'</span>]</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>model2.<span class="bu">compile</span>(optimizer <span class="op">=</span> <span class="st">"adam"</span>,</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>              loss <span class="op">=</span> losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>              metrics<span class="op">=</span>[<span class="st">'accuracy'</span>]</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>model3.<span class="bu">compile</span>(optimizer <span class="op">=</span> <span class="st">"adam"</span>,</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>              loss <span class="op">=</span> losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>              metrics<span class="op">=</span>[<span class="st">'accuracy'</span>]</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>callback <span class="op">=</span> keras.callbacks.EarlyStopping(monitor<span class="op">=</span><span class="st">'val_loss'</span>, patience<span class="op">=</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This code is responsible for compiling the three models (<code>model1</code>, <code>model2</code>, and <code>model3</code>) and setting up an early stopping callback for the training process.</p>
<p><strong>Model Compilation</strong>: - <code>model1.compile(optimizer="adam", loss=losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])</code>: compiles <code>model1</code> with the following settings: - <code>optimizer="adam"</code>: Specifies the Adam optimizer for updating the model’s weights during training. - <code>loss=losses.SparseCategoricalCrossentropy(from_logits=True)</code>: Specifies the loss function to be used. The <code>SparseCategoricalCrossentropy</code> loss is suitable for multi-class classification problems where the target labels are integer-encoded (e.g., 0, 1, 2, …). The <code>from_logits=True</code> parameter indicates that the model output is not yet passed through a softmax activation function, which will be done internally by the loss function. - <code>metrics=['accuracy']</code>: Specifies the evaluation metric to be tracked during training and testing. In this case, the accuracy metric is used, which measures the fraction of correctly classified samples.</p>
<ul>
<li>The same compilation steps are repeated for <code>model2</code> and <code>model3</code>.</li>
</ul>
<p><strong>Early Stopping Callback</strong>: - <code>callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)</code>: This line creates an <code>EarlyStopping</code> callback object, which monitors the validation loss (<code>val_loss</code>) during training and stops the training process if the validation loss does not decrease for a certain number of epochs (specified by <code>patience=5</code>).</p>
<ul>
<li><p>Early stopping is a regularization technique used to prevent overfitting by stopping the training process when the model performance on the validation set stops improving. This can help save computational resources and prevent the model from overfitting to the training data.</p></li>
<li><p>The <code>monitor='val_loss'</code> parameter specifies that the callback should monitor the validation loss. If you want to monitor a different metric, such as validation accuracy (<code>val_accuracy</code>), you can change this parameter accordingly.</p></li>
<li><p>The <code>patience=5</code> parameter means that the training process will stop if the validation loss does not decrease for 5 consecutive epochs.</p></li>
</ul>
<p>After compiling the models and setting up the early stopping callback, you can proceed to train the models using methods like <code>model.fit()</code> or <code>model.fit_generator()</code>. The early stopping callback will be applied during the training process, and the training will stop automatically if the specified criteria are met (in this case, if the validation loss does not decrease for 5 consecutive epochs). We can see it shortly.</p>
</section>
<section id="model-training-1" class="level1">
<h1>5. Model Training</h1>
<p>Things are quite similar to the last time:</p>
<p><code>epochs=20</code>: This parameter sets the number of epochs (complete passes through the training dataset) for the training process. In this case, the training will run for 20 epochs.</p>
<p><code>callbacks=[callback]</code>: This parameter specifies a list of callbacks to be applied during the training process. In this case, the list contains a single callback object <code>callback</code>, which was defined earlier as <code>callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)</code>. This callback will monitor the validation loss and stop the training if it does not decrease for 5 consecutive epochs, helping to prevent overfitting.</p>
<p><code>verbose=True</code>: This parameter controls the verbosity of the training output. When set to <code>True</code>, it will print the progress of the training process, including the loss and metric values for each epoch.</p>
<p>In summary, this line starts the training process for <code>model1</code> using the specified training dataset (<code>train</code>), validation dataset (<code>val</code>), and training parameters (<code>epochs=20</code>, <code>callbacks=[callback]</code>, <code>verbose=True</code>). The training history, containing information about the loss and metric values at each epoch, is stored in the <code>history1</code> variable. During the training process, the early stopping callback will monitor the validation loss and stop the training if it does not decrease for 5 consecutive epochs, helping to prevent overfitting.</p>
<p>We will do the same thing for the other 2 models.</p>
<div id="cell-51" class="cell" data-outputid="cc1989eb-3d6f-4a8e-aa07-ee6a4a1f4c3b" data-execution_count="26">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>history1 <span class="op">=</span> model1.fit(train,</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>                    validation_data<span class="op">=</span>val,</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>                    epochs <span class="op">=</span> <span class="dv">20</span>,</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>                    callbacks<span class="op">=</span>[callback],</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>                    verbose <span class="op">=</span> <span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 68s 4ms/step - accuracy: 0.5175 - loss: 0.6937 - val_accuracy: 0.5150 - val_loss: 0.6931
Epoch 2/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 63s 3ms/step - accuracy: 0.5250 - loss: 0.6923 - val_accuracy: 0.5150 - val_loss: 0.6931
Epoch 3/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 61s 3ms/step - accuracy: 0.5250 - loss: 0.6923 - val_accuracy: 0.5150 - val_loss: 0.6931
Epoch 4/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 61s 3ms/step - accuracy: 0.5250 - loss: 0.6923 - val_accuracy: 0.5150 - val_loss: 0.6931
Epoch 5/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 64s 4ms/step - accuracy: 0.5250 - loss: 0.6923 - val_accuracy: 0.5150 - val_loss: 0.6931
Epoch 6/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 62s 3ms/step - accuracy: 0.5250 - loss: 0.6923 - val_accuracy: 0.5150 - val_loss: 0.6931</code></pre>
</div>
</div>
<div id="cell-52" class="cell" data-outputid="b57aead7-f963-4c51-d7cd-a626ebf3f9fb" data-execution_count="27">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>history2 <span class="op">=</span> model2.fit(train,</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>                    validation_data<span class="op">=</span>val,</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>                    epochs <span class="op">=</span> <span class="dv">20</span>,</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>                    callbacks<span class="op">=</span>[callback],</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>                    verbose <span class="op">=</span> <span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 64s 3ms/step - accuracy: 0.7399 - loss: 0.4599 - val_accuracy: 0.8908 - val_loss: 0.2152
Epoch 2/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 63s 4ms/step - accuracy: 0.9142 - loss: 0.2142 - val_accuracy: 0.9632 - val_loss: 0.1042
Epoch 3/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 64s 4ms/step - accuracy: 0.9299 - loss: 0.1766 - val_accuracy: 0.9595 - val_loss: 0.1088
Epoch 4/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 64s 4ms/step - accuracy: 0.9390 - loss: 0.1568 - val_accuracy: 0.9461 - val_loss: 0.1306
Epoch 5/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 63s 3ms/step - accuracy: 0.9409 - loss: 0.1508 - val_accuracy: 0.9624 - val_loss: 0.0994
Epoch 6/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 63s 4ms/step - accuracy: 0.9474 - loss: 0.1344 - val_accuracy: 0.9652 - val_loss: 0.0916
Epoch 7/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 64s 4ms/step - accuracy: 0.9499 - loss: 0.1326 - val_accuracy: 0.9581 - val_loss: 0.1014
Epoch 8/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 63s 4ms/step - accuracy: 0.9522 - loss: 0.1207 - val_accuracy: 0.9670 - val_loss: 0.0879
Epoch 9/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 63s 4ms/step - accuracy: 0.9580 - loss: 0.1154 - val_accuracy: 0.9187 - val_loss: 0.2010
Epoch 10/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 64s 4ms/step - accuracy: 0.9587 - loss: 0.1070 - val_accuracy: 0.9779 - val_loss: 0.0779
Epoch 11/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 63s 4ms/step - accuracy: 0.9586 - loss: 0.1088 - val_accuracy: 0.9733 - val_loss: 0.0763
Epoch 12/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 62s 3ms/step - accuracy: 0.9617 - loss: 0.1045 - val_accuracy: 0.9804 - val_loss: 0.0723
Epoch 13/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 64s 4ms/step - accuracy: 0.9617 - loss: 0.0997 - val_accuracy: 0.9439 - val_loss: 0.1411
Epoch 14/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 62s 3ms/step - accuracy: 0.9618 - loss: 0.0988 - val_accuracy: 0.9710 - val_loss: 0.0836
Epoch 15/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 63s 4ms/step - accuracy: 0.9645 - loss: 0.0928 - val_accuracy: 0.9644 - val_loss: 0.0895
Epoch 16/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 63s 4ms/step - accuracy: 0.9644 - loss: 0.0942 - val_accuracy: 0.9719 - val_loss: 0.0841
Epoch 17/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 63s 4ms/step - accuracy: 0.9670 - loss: 0.0888 - val_accuracy: 0.9755 - val_loss: 0.0734</code></pre>
</div>
</div>
<div id="cell-53" class="cell" data-outputid="97f2cac1-9732-45a5-c622-0fe189d16be4" data-execution_count="28">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>history3 <span class="op">=</span> model3.fit(train,</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>                    validation_data<span class="op">=</span>val,</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>                    epochs <span class="op">=</span> <span class="dv">20</span>,</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>                    callbacks<span class="op">=</span>[callback],</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>                    verbose <span class="op">=</span> <span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 86s 5ms/step - accuracy: 0.9638 - loss: 0.1010 - val_accuracy: 0.9813 - val_loss: 0.0689
Epoch 2/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 86s 5ms/step - accuracy: 0.9652 - loss: 0.0918 - val_accuracy: 0.9681 - val_loss: 0.0971
Epoch 3/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 86s 5ms/step - accuracy: 0.9667 - loss: 0.0890 - val_accuracy: 0.9808 - val_loss: 0.0675
Epoch 4/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 87s 5ms/step - accuracy: 0.9672 - loss: 0.0900 - val_accuracy: 0.9782 - val_loss: 0.0722
Epoch 5/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 84s 5ms/step - accuracy: 0.9699 - loss: 0.0821 - val_accuracy: 0.9808 - val_loss: 0.0667
Epoch 6/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 84s 5ms/step - accuracy: 0.9695 - loss: 0.0821 - val_accuracy: 0.9791 - val_loss: 0.0684
Epoch 7/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 85s 5ms/step - accuracy: 0.9713 - loss: 0.0810 - val_accuracy: 0.9782 - val_loss: 0.0698
Epoch 8/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 90s 5ms/step - accuracy: 0.9694 - loss: 0.0804 - val_accuracy: 0.9820 - val_loss: 0.0671
Epoch 9/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 89s 5ms/step - accuracy: 0.9701 - loss: 0.0820 - val_accuracy: 0.9808 - val_loss: 0.0645
Epoch 10/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 88s 5ms/step - accuracy: 0.9692 - loss: 0.0794 - val_accuracy: 0.9833 - val_loss: 0.0645
Epoch 11/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 89s 5ms/step - accuracy: 0.9720 - loss: 0.0769 - val_accuracy: 0.9791 - val_loss: 0.0699
Epoch 12/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 88s 5ms/step - accuracy: 0.9744 - loss: 0.0727 - val_accuracy: 0.9804 - val_loss: 0.0652
Epoch 13/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 88s 5ms/step - accuracy: 0.9720 - loss: 0.0750 - val_accuracy: 0.9804 - val_loss: 0.0674
Epoch 14/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 88s 5ms/step - accuracy: 0.9747 - loss: 0.0729 - val_accuracy: 0.9815 - val_loss: 0.0643
Epoch 15/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 91s 5ms/step - accuracy: 0.9710 - loss: 0.0753 - val_accuracy: 0.9715 - val_loss: 0.0799
Epoch 16/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 90s 5ms/step - accuracy: 0.9740 - loss: 0.0717 - val_accuracy: 0.9815 - val_loss: 0.0644
Epoch 17/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 91s 5ms/step - accuracy: 0.9752 - loss: 0.0684 - val_accuracy: 0.9755 - val_loss: 0.0761
Epoch 18/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 92s 5ms/step - accuracy: 0.9745 - loss: 0.0700 - val_accuracy: 0.9802 - val_loss: 0.0674
Epoch 19/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 87s 5ms/step - accuracy: 0.9770 - loss: 0.0674 - val_accuracy: 0.9824 - val_loss: 0.0610
Epoch 20/20
17959/17959 ━━━━━━━━━━━━━━━━━━━━ 88s 5ms/step - accuracy: 0.9783 - loss: 0.0658 - val_accuracy: 0.9833 - val_loss: 0.0597</code></pre>
</div>
</div>
<p>The first two models stoped at Epoch 6/20, 17/20 indicates that it did decrease for 5 consecutive epochs, helping to prevent overfitting.</p>
<p>val_accuracy range for model1 stays at 0.51 val_accuracy range for model2: 0.8908 - 0.9804 val_accuracy range for model3: 0.9681 - 0.9833</p>
<p>From this, we could see model3, which takes both <code>title</code> and <code>text</code> performs the best!</p>
<p>Here are some interesting figures that might help you understand the learning rate of each model during the whole process.</p>
<p>This is just to save weights in the model if you want to plot by yourself without runing the model, since model runing is sometimes time-consuming.</p>
<div id="cell-56" class="cell" data-outputid="29456b0c-7677-44a7-b6eb-e0f0b4bcf589" data-execution_count="33">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>plt.plot(history1.history[<span class="st">"accuracy"</span>], label <span class="op">=</span> <span class="st">"training"</span>)</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>plt.plot(history1.history[<span class="st">"val_accuracy"</span>], label <span class="op">=</span> <span class="st">"validation"</span>)</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>plt.gca().<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">"epoch"</span>, ylabel <span class="op">=</span> <span class="st">"model1-accuracy"</span>)</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="fl">0.5</span>, <span class="dv">1</span>)</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-30-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>There might be some obvious overfitting in model1, and since the line is constant, the model does not display a active learning tendency.</p>
<div id="cell-58" class="cell" data-outputid="d9fcf784-185c-4f7f-e525-111de7fbad78" data-execution_count="34">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>plt.plot(history2.history[<span class="st">"accuracy"</span>], label <span class="op">=</span> <span class="st">"training"</span>)</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>plt.plot(history2.history[<span class="st">"val_accuracy"</span>], label <span class="op">=</span> <span class="st">"validation"</span>)</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>plt.gca().<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">"epoch"</span>, ylabel <span class="op">=</span> <span class="st">"model2-accuracy"</span>)</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="fl">0.5</span>, <span class="dv">1</span>)</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-31-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-59" class="cell" data-outputid="a1202898-0377-43f1-ffdd-9d21a2a2799d" data-execution_count="35">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>plt.plot(history3.history[<span class="st">"accuracy"</span>], label <span class="op">=</span> <span class="st">"training"</span>)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>plt.plot(history3.history[<span class="st">"val_accuracy"</span>], label <span class="op">=</span> <span class="st">"validation"</span>)</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>plt.gca().<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">"epoch"</span>, ylabel <span class="op">=</span> <span class="st">"model3-accuracy"</span>)</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="fl">0.5</span>, <span class="dv">1</span>)</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-32-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Overfitting is not as strong as the case last time since the training performance only over the validation performance for a little bit, which might caused by the usage of early stopping.</p>
</section>
<section id="model-evaluation-1" class="level1">
<h1>6. Model Evaluation</h1>
<p>Now let’s read the test data.</p>
<div id="cell-63" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>test_url <span class="op">=</span> <span class="st">"https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_test.csv?raw=true"</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(test_url)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Make sure you do the same things to the test data — that’s why we need a pipline.</p>
<div id="cell-65" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>test_data <span class="op">=</span> make_dataset(data)</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>test_data <span class="op">=</span> test_data.<span class="bu">map</span>(expand_dim)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-66" class="cell" data-outputid="965c6e1a-8cd4-4b73-e34b-4b0935140f57" data-execution_count="38">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>model3.evaluate(test_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>22449/22449 ━━━━━━━━━━━━━━━━━━━━ 47s 2ms/step - accuracy: 0.9811 - loss: 0.0718</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>[0.06856698542833328, 0.9815582036972046]</code></pre>
</div>
</div>
<p>Since model3 is our best model, we use model3 on test data and achieved 0.0.9815582036972046 overall, what a great model we’ve built!!!</p>
</section>
<section id="embedding-visualization" class="level1">
<h1>7. Embedding visualization</h1>
<p>Word embeddings are often produced as intermediate stages in many machine learning algorithms. In fact, we already made one – it’s the <code>Embedding</code> layer at the base of our model. Let’s take a look at the embedding layer to see how our own model represents words in a vector space.</p>
<div id="cell-70" class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> model3.get_layer(<span class="st">'title_embedding'</span>).get_weights()[<span class="dv">0</span>]<span class="co"># get the weights from the embedding layer</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>vocab <span class="op">=</span> vectorize_layer.get_vocabulary()<span class="co"># get the vocabulary from our data prep for later</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The collection of weights is 3-dimensional. For plotting in 2 dimensions, we have several choices for how to reduce the data to a 2d representation. A very simple and standard approach is our friend, principal component analysis (PCA).</p>
<p>PCA stands for Principal Component Analysis. It is a widely used technique in machine learning and data analysis for dimensionality reduction and feature extraction.</p>
<p>PCA is an unsupervised linear transformation technique that aims to find a new set of uncorrelated features called principal components. These principal components are ordered based on their ability to capture the variance in the original data. The first principal component captures the maximum possible variance, the second principal component captures the second-highest variance, and so on.</p>
<p>The main steps involved in PCA are:</p>
<ol type="1">
<li><p><strong>Standardize the data</strong>: The input features are standardized by subtracting the mean and dividing by the standard deviation to ensure that all features are on a similar scale.</p></li>
<li><p><strong>Compute the covariance matrix</strong>: The covariance matrix is calculated to capture the relationships between the features.</p></li>
<li><p><strong>Calculate the eigenvectors and eigenvalues</strong>: The eigenvectors and corresponding eigenvalues of the covariance matrix are computed. The eigenvectors represent the principal components, and the eigenvalues represent the amount of variance captured by each principal component.</p></li>
<li><p><strong>Select the principal components</strong>: The eigenvectors with the highest eigenvalues are chosen as the principal components, as they capture the most variance in the data.</p></li>
<li><p><strong>Project the data onto the principal components</strong>: The original data is projected onto the selected principal components, resulting in a new dataset with fewer dimensions (principal components) while retaining most of the important information.</p></li>
</ol>
<p>PCA is useful in various applications, including:</p>
<ol type="1">
<li><p><strong>Dimensionality reduction</strong>: PCA can be used to reduce the number of features in a dataset while retaining most of the important information, making the data more manageable and computationally efficient for further analysis or modeling.</p></li>
<li><p><strong>Data visualization</strong>: By projecting high-dimensional data onto a lower-dimensional subspace (e.g., 2D or 3D), PCA can aid in visualizing and exploring complex datasets.</p></li>
<li><p><strong>Noise reduction</strong>: PCA can help remove noise or redundant information from the data by keeping only the principal components that capture the most significant patterns.</p></li>
<li><p><strong>Feature extraction</strong>: The principal components obtained from PCA can be used as new, uncorrelated features for further analysis or modeling.</p></li>
</ol>
<div id="cell-72" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> pca.fit_transform(weights)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-73" class="cell" data-outputid="939a5f20-c013-4656-c85e-10644853627b" data-execution_count="41">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>embedding_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'word'</span> : vocab,</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'x0'</span>   : weights[:,<span class="dv">0</span>],</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'x1'</span>   : weights[:,<span class="dv">1</span>]</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>embedding_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">

  <div id="df-e5d2c965-fd1b-4a75-a797-7d6a51f27b54" class="colab-df-container">
    <div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">word</th>
<th data-quarto-table-cell-role="th">x0</th>
<th data-quarto-table-cell-role="th">x1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td></td>
<td>0.356733</td>
<td>-0.126862</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>[UNK]</td>
<td>34.395100</td>
<td>0.346069</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>said</td>
<td>2.507210</td>
<td>0.529500</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>trump</td>
<td>2.315338</td>
<td>0.045322</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>us</td>
<td>-12.205403</td>
<td>0.066065</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1995</td>
<td>questioned</td>
<td>0.706504</td>
<td>-0.048583</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1996</td>
<td>presence</td>
<td>0.127328</td>
<td>-0.245068</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1997</td>
<td>mnuchin</td>
<td>-1.282213</td>
<td>-0.226332</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1998</td>
<td>footage</td>
<td>0.789734</td>
<td>-0.005336</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1999</td>
<td>oversight</td>
<td>-0.154048</td>
<td>-0.094105</td>
</tr>
</tbody>
</table>

<p>2000 rows × 3 columns</p>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-e5d2c965-fd1b-4a75-a797-7d6a51f27b54')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-e5d2c965-fd1b-4a75-a797-7d6a51f27b54 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-e5d2c965-fd1b-4a75-a797-7d6a51f27b54');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-c802f959-37a9-4d9f-8e4a-3c766080827e">
  <button class="colab-df-quickchart" onclick="quickchart('df-c802f959-37a9-4d9f-8e4a-3c766080827e')" title="Suggest charts" style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-c802f959-37a9-4d9f-8e4a-3c766080827e button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

  <div id="id_7e84e51e-44c9-4e59-b412-8448caa95e8b">
    <style>
      .colab-df-generate {
        background-color: #E8F0FE;
        border: none;
        border-radius: 50%;
        cursor: pointer;
        display: none;
        fill: #1967D2;
        height: 32px;
        padding: 0 0 0 0;
        width: 32px;
      }

      .colab-df-generate:hover {
        background-color: #E2EBFA;
        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
        fill: #174EA6;
      }

      [theme=dark] .colab-df-generate {
        background-color: #3B4455;
        fill: #D2E3FC;
      }

      [theme=dark] .colab-df-generate:hover {
        background-color: #434B5C;
        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
        fill: #FFFFFF;
      }
    </style>
    <button class="colab-df-generate" onclick="generateWithVariable('embedding_df')" title="Generate code using this dataframe." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <path d="M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z"></path>
  </svg>
    </button>
    <script>
      (() => {
      const buttonEl =
        document.querySelector('#id_7e84e51e-44c9-4e59-b412-8448caa95e8b button.colab-df-generate');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      buttonEl.onclick = () => {
        google.colab.notebook.generateWithVariable('embedding_df');
      }
      })();
    </script>
  </div>

    </div>
  </div>
</div>
</div>
<div id="cell-74" class="cell" data-outputid="f1946fbb-6c01-4c6e-fb08-e787fb066c86">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> px.scatter(embedding_df,</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>                 x <span class="op">=</span> <span class="st">"x0"</span>,</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>                 y <span class="op">=</span> <span class="st">"x1"</span>,</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>                 size <span class="op">=</span> <span class="bu">list</span>(np.ones(<span class="bu">len</span>(embedding_df))),</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>                 size_max <span class="op">=</span> <span class="dv">3</span>,</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>                 hover_name <span class="op">=</span> <span class="st">"word"</span>)</span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a>fig.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="newplot.png" title="Title" class="img-fluid figure-img"></p>
<figcaption>alt text</figcaption>
</figure>
</div>
<div id="cell-76" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>pronounce_close <span class="op">=</span> [<span class="st">"2"</span>, <span class="st">"too"</span>]</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>meaning_close <span class="op">=</span> [<span class="st">"good"</span>, <span class="st">"great"</span>]</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>meaning_opposite <span class="op">=</span> [<span class="st">"yes"</span>, <span class="st">"no"</span>]</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gender_mapper(x):</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> x <span class="kw">in</span> pronounce_close:</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">1</span></span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> x <span class="kw">in</span> pronounce_close:</span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">4</span></span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> x <span class="kw">in</span> meaning_opposite:</span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">5</span></span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">0</span></span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a>embedding_df[<span class="st">"highlight"</span>] <span class="op">=</span> embedding_df[<span class="st">"word"</span>].<span class="bu">apply</span>(gender_mapper)</span>
<span id="cb56-16"><a href="#cb56-16" aria-hidden="true" tabindex="-1"></a>embedding_df[<span class="st">"size"</span>]      <span class="op">=</span> np.array(<span class="fl">1.0</span> <span class="op">+</span> <span class="dv">50</span><span class="op">*</span>(embedding_df[<span class="st">"highlight"</span>] <span class="op">&gt;</span> <span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-77" class="cell" data-outputid="f66aa823-a38b-4468-dc43-53185314ac4a">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> px.scatter(embedding_df,</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>                 x <span class="op">=</span> <span class="st">"x0"</span>,</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>                 y <span class="op">=</span> <span class="st">"x1"</span>,</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>                 color <span class="op">=</span> <span class="st">"highlight"</span>,</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>                 size <span class="op">=</span> <span class="bu">list</span>(embedding_df[<span class="st">"size"</span>]),</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a>                 size_max <span class="op">=</span> <span class="dv">10</span>,</span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>                 hover_name <span class="op">=</span> <span class="st">"word"</span>)</span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>fig.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="newplot2.png" title="Title1" class="img-fluid figure-img"></p>
<figcaption>alt text</figcaption>
</figure>
</div>
<ol type="1">
<li><p>“2” and “too” can sometimes be used interchangeably in informal written communication, especially in contexts like text messaging or online forums where brevity and informality are common. I think that’s why they are close located.</p></li>
<li><p>The proximity of “good” and “great” in the word embedding space indicates that these two adjectives are likely to be synonymous or have similar meanings.</p></li>
<li><p>The fact that “yes” and “no” are located far apart in the embedding space suggests that these two words have opposite meanings. ”</p></li>
</ol>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>